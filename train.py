# -*- coding: utf-8 -*-
"""Conditional_SLE-GAN_template.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GADBacbjtpsiWWnlS_gs8KPgIzphobf3

# 概要
SLE-GAN (Lightweight GAN)に、生成画像の条件指定機能を追加

# 使用するGPUを指定
"""

import os
# dual GPUなら、"0,1"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

"""# 使用するGPUメモリの制限"""

import tensorflow as tf

# tf.compat.v1.disable_eager_execution()

tf_ver = tf.__version__

GPU_ID = 0
if tf_ver >= "2.1.0":
    physical_devices = tf.config.list_physical_devices('GPU')
    tf.config.list_physical_devices('GPU')
    tf.config.set_visible_devices(physical_devices[GPU_ID], 'GPU')
    tf.config.experimental.set_memory_growth(physical_devices[GPU_ID], True)
elif tf_ver.startswith('1.'):
    from tensorflow.keras.backend import set_session
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    config.log_device_placement = True
    sess = tf.Session(config=config)
    set_session(sess)

tf.executing_eagerly()

"""# 実験用環境変数"""

RUN = 2
RESOLUTION = 256
BATCH_SIZE = 2
EPOCHS = 200
IMAGE_DIR = 'path to top directory of images'
OVERRIDE = True
ANNOTATION_FILE = 'path to annotation csv file'

generator_weights = None
discriminator_weights = None
G_learning_rate = 2e-4
D_learning_rate = 2e-4
FID = True
DIFF_AUGMENT = True
FID_FREQUENCY = 1

"""# 教師データ生成クラス"""

from PIL import Image, ImageOps
import numpy as np
import random
from tensorflow.keras.preprocessing.image import img_to_array, array_to_img
import tensorflow as tf

class ImageSequence(tf.keras.utils.Sequence):
    def __init__(self, file_list, conditional_vectors, batch_size, resolution, shuffle=True, horizontal_flip=False):
        self.file_list = list(file_list)
        self.conditional_vectors = conditional_vectors
        self.batch_size = batch_size
        self.resolution = resolution
        self.shuffle = shuffle
        self.horizontal_flip = horizontal_flip

        self.indexes = np.arange(len(self.file_list))
        if self.shuffle:
            random.shuffle(self.indexes)
            
    def __getitem__(self, index):
        x = []
        y = []
        
        idx = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]

#         print(len(self.conditional_vectors))
        for i in idx:
            f = self.file_list[i]
            
            img = Image.open(f)

            if img.mode != 'RGB':
                img = img.convert('RGB')
            
#             if self.horizontal_flip and random.random() > 0.5:
#                 img = ImageOps.mirror(img)

            img = img.resize((self.resolution, self.resolution), Image.BILINEAR)
            img = img_to_array(img).astype('float32')
            img -= 127.5
            img /= 127.5

            x.append(np.expand_dims(img, axis=0))
            y.append(np.expand_dims(self.conditional_vectors[i], axis=0))
                    
        return np.concatenate(x, axis=0), np.concatenate(y, axis=0)
        
    def __len__(self):
        return len(self.indexes) // self.batch_size

    def on_epoch_end(self):
        if self.shuffle:
            random.shuffle(self.indexes)

"""# アノテーションファイルを読み込む
* CSVフォーマット
* ヘッダなし
* 1列目：画像ファイルのパス。起点画像フォルダからの相対パス
* 2列目以降：条件ベクトル
"""

import os

def load_annotation(image_dir, file):
    files = []
    condition_vectors = []
    
    with open(file, 'r', encoding='utf8') as f:
        lines = f.readlines()
        for l in lines:
            ws = l.rstrip().split(',')
            files.append(os.path.join(image_dir, ws[0]))
            tmp = np.array([float(v) for v in ws[1:]]).astype('float32')
            condition_vectors.append(np.expand_dims(tmp, axis=0))
            
    return files, np.concatenate(condition_vectors, axis=0)

"""# 学習

## モジュールのインポート
"""

import shutil
from pathlib import Path
import tensorflow as tf
import sle_gan
import numpy as np

# args = sle_gan.get_args()
# print(args)

# For debugging:
# tf.config.experimental_run_functions_eagerly(True)

"""## 実験環境セットアップ"""

physical_devices = tf.config.list_physical_devices("GPU")
_ = [tf.config.experimental.set_memory_growth(x, True) for x in physical_devices]

experiments_folder = Path("results") / f'run{RUN}'
if experiments_folder.is_dir():
    if OVERRIDE:
        shutil.rmtree(experiments_folder)
    else:
        raise FileExistsError("Experiment already exists")
checkpoints_folder = experiments_folder / "checkpoints"
checkpoints_folder.mkdir(parents=True)
logs_folder = experiments_folder / "tensorboard_logs"
logs_folder.mkdir(parents=True)

"""## 教師データ生成"""

file_list, condition_vectors = load_annotation(IMAGE_DIR, ANNOTATION_FILE)
NUM_CLASSES = condition_vectors.shape[-1]

# 訓練データ用シーケンス
dataset = ImageSequence(file_list, condition_vectors, batch_size=BATCH_SIZE, resolution=RESOLUTION,
                        shuffle=True)

"""## Generator初期化"""

G = sle_gan.Generator(RESOLUTION)

sample_G_output = G.initialize(BATCH_SIZE, condition_vectors[:BATCH_SIZE].astype('float32'))
if generator_weights is not None:
    G.load_weights(generator_weights)
    print("Weights are loaded for G")
print(f"[Model G] output shape: {sample_G_output.shape}")

"""## Discriminator初期化"""

D = sle_gan.Discriminator(RESOLUTION)
sample_D_output = D.initialize(BATCH_SIZE, condition_vectors[:BATCH_SIZE].astype('float32'))
if discriminator_weights is not None:
    D.load_weights(discriminator_weights)
    print("Weights are loaded for D")
print(f"[Model D] real_fake output shape: {sample_D_output[0].shape}")
print(f"[Model D] image output shape{sample_D_output[1].shape}")
print(f"[Model D] image part output shape{sample_D_output[2].shape}")

"""## Fréchet Inception Distance評価用セットアップ"""

if FID:
    # Model for the FID calculation
    fid_inception_model = sle_gan.InceptionModel(height=RESOLUTION, width=RESOLUTION)

test_input_size = 25
test_dataset = ImageSequence(file_list, condition_vectors, batch_size=test_input_size, resolution=RESOLUTION,
                             shuffle=True)
FID_NUMBER_OF_IMAGES = min(len(file_list), 128)

test_image_src, test_conditional_vectors = test_dataset.__getitem__(0)

# 生成器テスト用入力潜在ベクトル
test_input_for_generation = sle_gan.data.create_latent_vectors(test_input_size, test_conditional_vectors)

# 識別器テスト用入力画像
test_images = sle_gan.data.create_discriminator_inputs(test_image_src, test_conditional_vectors)

tb_file_writer = tf.summary.create_file_writer(str(logs_folder))
tb_file_writer.set_as_default()

"""## 最適化アルゴリズム"""

G_optimizer = tf.optimizers.Adam(learning_rate=G_learning_rate)
D_optimizer = tf.optimizers.Adam(learning_rate=D_learning_rate)

"""## 損失"""

G_loss_metric = tf.keras.metrics.Mean()
D_loss_metric = tf.keras.metrics.Mean()
D_real_fake_loss_metric = tf.keras.metrics.Mean()
D_I_reconstruction_loss_metric = tf.keras.metrics.Mean()
D_I_part_reconstruction_loss_metric = tf.keras.metrics.Mean()

"""## データ拡張"""

diff_augment_policies = None
if DIFF_AUGMENT:
    diff_augment_policies = "color,translation,cutout"

"""## 学習"""

for epoch in range(EPOCHS):
    print(f"Epoch {epoch} -------------")
    for step, image_batch in enumerate(dataset):
        images, conditional_vectors = image_batch
        G_loss, D_loss, D_real_fake_loss, D_I_reconstruction_loss, D_I_part_reconstruction_loss = sle_gan.train_step(
            G=G,
            D=D,
            G_optimizer=G_optimizer,
            D_optimizer=D_optimizer,
            images=images,
            conditional_vectors=conditional_vectors,
            diff_augmenter_policies=diff_augment_policies)

        G_loss_metric(G_loss)
        D_loss_metric(D_loss)
        D_real_fake_loss_metric(D_real_fake_loss)
        D_I_reconstruction_loss_metric(D_I_reconstruction_loss)
        D_I_part_reconstruction_loss_metric(D_I_part_reconstruction_loss)

        if step % 100 == 0 and step != 0:
            print(f"\tStep {step} - "
                  f"G loss {G_loss_metric.result():.4f} | "
                  f"D loss {D_loss_metric.result():.4f} | "
                  f"D realfake loss {D_real_fake_loss_metric.result():.4f} | "
                  f"D I recon loss {D_I_reconstruction_loss_metric.result():.4f} | "
                  f"D I part recon loss {D_I_part_reconstruction_loss_metric.result():.4f}")

    if DIFF_AUGMENT:
        if epoch % FID_FREQUENCY == 0:
            fid_score = sle_gan.evaluation_step(inception_model=fid_inception_model,
                                                dataset=test_dataset,
                                                G=G,
                                                batch_size=test_input_size,
                                                image_height=RESOLUTION,
                                                image_width=RESOLUTION,
                                                nb_of_images_to_use=FID_NUMBER_OF_IMAGES)
            print(f"[FID] {fid_score:.2f}")
            tf.summary.scalar("FID_score", fid_score, epoch)

    tf.summary.scalar("G_loss/G_loss", G_loss_metric.result(), epoch)
    tf.summary.scalar("D_loss/D_loss", D_loss_metric.result(), epoch)
    tf.summary.scalar("D_loss/D_real_fake_loss", D_real_fake_loss_metric.result(), epoch)
    tf.summary.scalar("D_loss/D_I_reconstruction_loss", D_I_reconstruction_loss_metric.result(), epoch)
    tf.summary.scalar("D_loss/D_I_part_reconstruction_loss", D_I_part_reconstruction_loss_metric.result(), epoch)

    print(f"Epoch {epoch} - "
          f"G loss {G_loss_metric.result():.4f} | "
          f"D loss {D_loss_metric.result():.4f} | "
          f"D realfake loss {D_real_fake_loss_metric.result():.4f} | "
          f"D I recon loss {D_I_reconstruction_loss_metric.result():.4f} | "
          f"D I part recon loss {D_I_part_reconstruction_loss_metric.result():.4f}")

    G_loss_metric.reset_states()
    D_loss_metric.reset_states()
    D_real_fake_loss_metric.reset_states()
    D_I_part_reconstruction_loss_metric.reset_states()
    D_I_reconstruction_loss_metric.reset_states()

    # TODO: save weights only when the FID score gets better
    G.save_weights(str(checkpoints_folder / "G_checkpoint.h5"))
    D.save_weights(str(checkpoints_folder / "D_checkpoint.h5"))

    # Generate test images
    generated_images = G(test_input_for_generation, training=False)
    generated_images = sle_gan.postprocess_images(generated_images, dtype=tf.uint8).numpy()
    sle_gan.visualize_images_on_grid_and_save(epoch, generated_images, experiments_folder / "generated_images",
                                              5, 5)

    # Generate reconstructions from Discriminator
    _, decoded_images, decoded_part_images = D(test_images, training=False)
    decoded_images = sle_gan.postprocess_images(decoded_images, dtype=tf.uint8).numpy()
    decoded_part_images = sle_gan.postprocess_images(decoded_part_images, dtype=tf.uint8).numpy()
    sle_gan.visualize_images_on_grid_and_save(epoch, decoded_images, experiments_folder / "reconstructed_whole_images",
                                              5, 5)
    sle_gan.visualize_images_on_grid_and_save(epoch, decoded_part_images,
                                              experiments_folder / "reconstructed_part_images", 5, 5)

